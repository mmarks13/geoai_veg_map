{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c69e3c0-fb09-496d-a25e-a572eb8f11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"model/\"))\n",
    "# sys.path.append(\"..\")\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970ad7d6-80b5-44bb-9847-fb60cf5721bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "from model.src.datamodule import ClayDataModule\n",
    "from model.src.model import ClayMAEModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd91b9b-3f73-47e2-9587-70d1d125b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/ubuntu/data\"\n",
    "CHECKPOINT_PATH = \"model/checkpoints/v1/clay-v1-base.ckpt\"\n",
    "METADATA_PATH = \"model/configs/metadata.yaml\"\n",
    "CHIP_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732cf373-b4ce-46d0-99bd-8b7cffe60b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# print(timm.list_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cad73c5-c910-4f78-b6fc-df11dace9e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As we want to visualize the embeddings from the model,\n",
    "# we neither mask the input image or shuffle the patches\n",
    "module = ClayMAEModule.load_from_checkpoint(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    metadata_path=METADATA_PATH,\n",
    "    mask_ratio=0.0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "module.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f886e-f0f0-4922-bee1-d0744b08bced",
   "metadata": {},
   "source": [
    "# Preparing Earth Observation Data with `stacchip`\n",
    "\n",
    "This script demonstrates how to use the `stacchip` library to process Earth observation data from a STAC catalog. It retrieves image chips from the specified collection, organizes them into batches, and saves them in the `.npz` format required by the `ClayDataModule`. \n",
    "\n",
    "### Overview:\n",
    "1. **STAC Catalog Query**: Fetch imagery from collections like NAIP, Landsat, or Sentinel-2.\n",
    "2. **Chipping and Indexing**: Dynamically generate image chips using `NoStatsChipIndexer` and `Chipper`.\n",
    "3. **Batching and Saving**: Save image chips in `.npz` format with placeholder metadata.\n",
    "4. **Integration**: Organize the output directory for seamless use with the `ClayDataModule`.\n",
    "\n",
    "Replace parameters like `COLLECTION_NAME`, `OUTPUT_DIR`, and `BATCH_SIZE` as needed for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461ee69-38ef-4895-963f-3b2e2e4960d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pystac_client\n",
    "from stacchip.indexer import NoStatsChipIndexer\n",
    "from stacchip.chipper import Chipper\n",
    "\n",
    "# Optimize GDAL settings for cloud-optimized reading\n",
    "os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n",
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\n",
    "\n",
    "# Parameters\n",
    "OUTPUT_DIR = \"/path/to/output/directory\"\n",
    "STAC_CATALOG_URL = \"https://earth-search.aws.element84.com/v1\"\n",
    "COLLECTION_NAME = \"naip\"  # Replace with appropriate collection name\n",
    "MAX_ITEMS = 100  # Number of items to fetch from the STAC catalog\n",
    "BATCH_SIZE = 128  # Chips per batch\n",
    "CHIP_SIZE = 256  # Chip resolution (H, W)\n",
    "\n",
    "# Create the output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Query the STAC catalog\n",
    "catalog = pystac_client.Client.open(STAC_CATALOG_URL)\n",
    "items = catalog.search(collections=[COLLECTION_NAME], max_items=MAX_ITEMS).item_collection()\n",
    "items_list = list(items)\n",
    "random.shuffle(items_list)  # Shuffle to select random items\n",
    "\n",
    "# Process each STAC item and create chips\n",
    "batch_pixels = []\n",
    "batch_lat_norm = []\n",
    "batch_lon_norm = []\n",
    "batch_week_norm = []\n",
    "batch_hour_norm = []\n",
    "\n",
    "for item_idx, item in enumerate(items_list):\n",
    "    print(f\"Processing item: {item.id}\")\n",
    "\n",
    "    # Index the chips in the item\n",
    "    indexer = NoStatsChipIndexer(item)\n",
    "    chipper = Chipper(indexer, assets=[\"image\"])  # Specify the assets to chip\n",
    "\n",
    "    # Retrieve chips from the item\n",
    "    for chip_id in random.sample(range(len(chipper)), 5):  # Adjust chip sampling as needed\n",
    "        _, _, chip = chipper[chip_id]\n",
    "        batch_pixels.append(chip[\"image\"])  # Add chip data (B, C, H, W)\n",
    "\n",
    "        # Add dummy normalized metadata (replace with real values if available)\n",
    "        lat_norm = np.zeros((1, 2), dtype=np.float32)\n",
    "        lon_norm = np.zeros((1, 2), dtype=np.float32)\n",
    "        week_norm = np.zeros((1, 2), dtype=np.float32)\n",
    "        hour_norm = np.zeros((1, 2), dtype=np.float32)\n",
    "\n",
    "        batch_lat_norm.append(lat_norm)\n",
    "        batch_lon_norm.append(lon_norm)\n",
    "        batch_week_norm.append(week_norm)\n",
    "        batch_hour_norm.append(hour_norm)\n",
    "\n",
    "        # Save batch when full or at the end of items\n",
    "        if len(batch_pixels) == BATCH_SIZE or (item_idx == len(items_list) - 1 and chip_id == 4):\n",
    "            # Format batch for saving\n",
    "            batch_pixels = np.stack(batch_pixels)  # (B, C, H, W)\n",
    "            batch_lat_norm = np.vstack(batch_lat_norm)\n",
    "            batch_lon_norm = np.vstack(batch_lon_norm)\n",
    "            batch_week_norm = np.vstack(batch_week_norm)\n",
    "            batch_hour_norm = np.vstack(batch_hour_norm)\n",
    "\n",
    "            # Save batch as .npz file\n",
    "            batch_index = item_idx // BATCH_SIZE\n",
    "            np.savez(\n",
    "                Path(OUTPUT_DIR) / f\"cube_{batch_index}.npz\",\n",
    "                pixels=batch_pixels,\n",
    "                lat_norm=batch_lat_norm,\n",
    "                lon_norm=batch_lon_norm,\n",
    "                week_norm=batch_week_norm,\n",
    "                hour_norm=batch_hour_norm,\n",
    "            )\n",
    "\n",
    "            # Reset batch\n",
    "            batch_pixels = []\n",
    "            batch_lat_norm = []\n",
    "            batch_lon_norm = []\n",
    "            batch_week_norm = []\n",
    "            batch_hour_norm = []\n",
    "\n",
    "print(\"Data preparation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc403528-0edd-4ff1-977f-f532143edf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import ClayDataModule\n",
    "\n",
    "DATA_DIR = \"/path/to/output/directory\"\n",
    "METADATA_PATH = \"model/configs/metadata.yaml\"\n",
    "CHIP_SIZE = 224\n",
    "\n",
    "dm = ClayDataModule(\n",
    "    data_dir=DATA_DIR,\n",
    "    metadata_path=METADATA_PATH,\n",
    "    size=CHIP_SIZE,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    ")\n",
    "dm.setup(stage=\"fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geoai-veg-map)",
   "language": "python",
   "name": "geoai-veg-map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
